{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NeSVoR2 Pipeline - Interactive Visualization Notebook\n",
    "\n",
    "This notebook provides an interactive walkthrough of the NeSVoR2 MRI super-resolution pipeline with detailed visualizations at each phase.\n",
    "\n",
    "## Pipeline Phases:\n",
    "1. **Load Inputs** - Load stacks, masks, and models\n",
    "2. **Segmentation** - 2D fetal brain masking\n",
    "3. **Bias Field Correction** - N4 algorithm\n",
    "4. **Assessment** - Stack quality metrics\n",
    "5. **Registration** - Motion correction (SVoRT)\n",
    "6. **Reconstruction** - NeSVoR training\n",
    "7. **Sampling** - Generate high-resolution volume\n",
    "8. **Save Outputs** - Export results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import logging\n",
    "from argparse import Namespace\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Import NeSVoR modules\n",
    "from utils import (\n",
    "    load_stack,\n",
    "    load_slices,\n",
    "    save_slices,\n",
    "    merge_args,\n",
    "    load_mask,\n",
    "    Volume,\n",
    "    Stack,\n",
    "    Slice,\n",
    ")\n",
    "from model.models import INR\n",
    "from model.train import train\n",
    "from model.sample import sample_volume, sample_slices\n",
    "from preprocess import (\n",
    "    stack_intersect,\n",
    "    otsu_thresholding,\n",
    "    thresholding,\n",
    "    n4_bias_field_correction,\n",
    "    brain_segmentation,\n",
    "    assess,\n",
    ")\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "print(\"‚úì Imports successful\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_slice_montage(stack: Stack, title: str = \"Stack Slices\", num_slices: int = 9, cmap: str = 'gray'):\n",
    "    \"\"\"\n",
    "    Display a montage of slices from a stack.\n",
    "    \n",
    "    Args:\n",
    "        stack: Stack object\n",
    "        title: Plot title\n",
    "        num_slices: Number of slices to display\n",
    "        cmap: Colormap for display\n",
    "    \"\"\"\n",
    "    n_total = stack.slices.shape[0]\n",
    "    indices = np.linspace(0, n_total - 1, min(num_slices, n_total), dtype=int)\n",
    "    \n",
    "    rows = int(np.ceil(np.sqrt(len(indices))))\n",
    "    cols = int(np.ceil(len(indices) / rows))\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 3, rows * 3))\n",
    "    axes = axes.flatten() if len(indices) > 1 else [axes]\n",
    "    \n",
    "    for idx, ax in enumerate(axes):\n",
    "        if idx < len(indices):\n",
    "            slice_idx = indices[idx]\n",
    "            slice_data = stack.slices[slice_idx, 0].cpu().numpy()\n",
    "            \n",
    "            ax.imshow(slice_data.T, cmap=cmap, origin='lower')\n",
    "            ax.set_title(f'Slice {slice_idx}/{n_total-1}')\n",
    "            ax.axis('off')\n",
    "        else:\n",
    "            ax.axis('off')\n",
    "    \n",
    "    plt.suptitle(title, fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_3d_views(volume_data: torch.Tensor, title: str = \"3D Volume Views\", masked: bool = False):\n",
    "    \"\"\"\n",
    "    Display axial, sagittal, and coronal views of a 3D volume.\n",
    "    \n",
    "    Args:\n",
    "        volume_data: 3D tensor (x, y, z)\n",
    "        title: Plot title\n",
    "        masked: Whether to use mask for background\n",
    "    \"\"\"\n",
    "    if isinstance(volume_data, torch.Tensor):\n",
    "        volume_data = volume_data.cpu().numpy()\n",
    "    \n",
    "    # Get middle slices\n",
    "    mid_x = volume_data.shape[0] // 2\n",
    "    mid_y = volume_data.shape[1] // 2\n",
    "    mid_z = volume_data.shape[2] // 2\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # Sagittal view (YZ plane)\n",
    "    axes[0].imshow(volume_data[mid_x, :, :].T, cmap='gray', origin='lower')\n",
    "    axes[0].set_title('Sagittal View (YZ)')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Coronal view (XZ plane)\n",
    "    axes[1].imshow(volume_data[:, mid_y, :].T, cmap='gray', origin='lower')\n",
    "    axes[1].set_title('Coronal View (XZ)')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    # Axial view (XY plane)\n",
    "    axes[2].imshow(volume_data[:, :, mid_z].T, cmap='gray', origin='lower')\n",
    "    axes[2].set_title('Axial View (XY)')\n",
    "    axes[2].axis('off')\n",
    "    \n",
    "    plt.suptitle(title, fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_stack_info(stack: Stack, stack_idx: int = 0):\n",
    "    \"\"\"\n",
    "    Display detailed information about a stack.\n",
    "    \n",
    "    Args:\n",
    "        stack: Stack object\n",
    "        stack_idx: Index of the stack\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Stack {stack_idx} Information\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Shape (slices):        {stack.slices.shape}\")\n",
    "    print(f\"Data type:             {stack.slices.dtype}\")\n",
    "    print(f\"Device:                {stack.slices.device}\")\n",
    "    print(f\"Resolution (x, y):     {stack.resolution_x:.3f} mm, {stack.resolution_y:.3f} mm\")\n",
    "    print(f\"Slice thickness:       {stack.thickness:.3f} mm\")\n",
    "    print(f\"Intensity range:       [{stack.slices.min().item():.2f}, {stack.slices.max().item():.2f}]\")\n",
    "    print(f\"Intensity mean:        {stack.slices.mean().item():.2f}\")\n",
    "    print(f\"Intensity std:         {stack.slices.std().item():.2f}\")\n",
    "    \n",
    "    if stack.mask is not None:\n",
    "        print(f\"Mask shape:            {stack.mask.shape}\")\n",
    "        print(f\"Masked voxels:         {stack.mask.sum().item()} / {stack.mask.numel()} ({100*stack.mask.sum().item()/stack.mask.numel():.1f}%)\")\n",
    "    else:\n",
    "        print(f\"Mask:                  None\")\n",
    "    \n",
    "    print(f\"Transformation shape:  {stack.transformation.shape if hasattr(stack, 'transformation') else 'N/A'}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "\n",
    "def show_intensity_histogram(stack: Stack, title: str = \"Intensity Distribution\", bins: int = 50):\n",
    "    \"\"\"\n",
    "    Display intensity histogram for a stack.\n",
    "    \n",
    "    Args:\n",
    "        stack: Stack object\n",
    "        title: Plot title\n",
    "        bins: Number of histogram bins\n",
    "    \"\"\"\n",
    "    data = stack.slices[stack.slices > 0].cpu().numpy().flatten()\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 4))\n",
    "    ax.hist(data, bins=bins, alpha=0.7, edgecolor='black')\n",
    "    ax.set_xlabel('Intensity')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.set_title(title)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def compare_stacks(stack1: Stack, stack2: Stack, title1: str = \"Before\", title2: str = \"After\", slice_idx: int = None):\n",
    "    \"\"\"\n",
    "    Side-by-side comparison of two stacks.\n",
    "    \n",
    "    Args:\n",
    "        stack1: First stack\n",
    "        stack2: Second stack\n",
    "        title1: Title for first stack\n",
    "        title2: Title for second stack\n",
    "        slice_idx: Specific slice to compare (default: middle slice)\n",
    "    \"\"\"\n",
    "    if slice_idx is None:\n",
    "        slice_idx = stack1.slices.shape[0] // 2\n",
    "    \n",
    "    slice1 = stack1.slices[slice_idx, 0].cpu().numpy()\n",
    "    slice2 = stack2.slices[slice_idx, 0].cpu().numpy()\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # Before\n",
    "    axes[0].imshow(slice1.T, cmap='gray', origin='lower')\n",
    "    axes[0].set_title(f'{title1} (Slice {slice_idx})')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # After\n",
    "    axes[1].imshow(slice2.T, cmap='gray', origin='lower')\n",
    "    axes[1].set_title(f'{title2} (Slice {slice_idx})')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    # Difference\n",
    "    diff = slice2 - slice1\n",
    "    im = axes[2].imshow(diff.T, cmap='RdBu_r', origin='lower', vmin=-np.abs(diff).max(), vmax=np.abs(diff).max())\n",
    "    axes[2].set_title('Difference')\n",
    "    axes[2].axis('off')\n",
    "    plt.colorbar(im, ax=axes[2], fraction=0.046, pad=0.04)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_training_metrics(metrics_dict: Dict[str, List[float]]):\n",
    "    \"\"\"\n",
    "    Plot training metrics over iterations.\n",
    "    \n",
    "    Args:\n",
    "        metrics_dict: Dictionary of metric names to values\n",
    "    \"\"\"\n",
    "    n_metrics = len(metrics_dict)\n",
    "    fig, axes = plt.subplots(1, n_metrics, figsize=(5 * n_metrics, 4))\n",
    "    \n",
    "    if n_metrics == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for idx, (name, values) in enumerate(metrics_dict.items()):\n",
    "        axes[idx].plot(values)\n",
    "        axes[idx].set_xlabel('Iteration')\n",
    "        axes[idx].set_ylabel(name)\n",
    "        axes[idx].set_title(f'{name} over Training')\n",
    "        axes[idx].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print(\"‚úì Visualization functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set up the pipeline parameters. You can modify these values for your specific use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create configuration\n",
    "args = Namespace(\n",
    "    # Input files (MODIFY THESE PATHS)\n",
    "    input_stacks=['stack1.nii.gz', 'stack2.nii.gz', 'stack3.nii.gz'],\n",
    "    stack_masks=None,  # Optional: ['mask1.nii.gz', 'mask2.nii.gz', 'mask3.nii.gz']\n",
    "    thicknesses=[3.0, 3.0, 3.0],  # Slice thickness in mm\n",
    "    volume_mask=None,  # Optional: 'volume_mask.nii.gz'\n",
    "    stacks_intersection=False,  # Create volume mask from stack intersection\n",
    "    \n",
    "    # Preprocessing options\n",
    "    segmentation=False,  # Enable 2D brain segmentation\n",
    "    bias_field_correction=False,  # Enable N4 bias correction\n",
    "    n_levels_bias=0,\n",
    "    skip_assessment=True,  # Skip quality assessment\n",
    "    metric='none',  # Options: 'ncc', 'matrix-rank', 'volume', 'iqa2d', 'iqa3d', 'none'\n",
    "    filter_method='none',  # Options: 'top', 'bottom', 'threshold', 'percentage', 'none'\n",
    "    cutoff=0.0,\n",
    "    batch_size_assess=8,\n",
    "    no_augmentation_assess=False,\n",
    "    background_threshold=0.0,\n",
    "    otsu_thresholding=False,\n",
    "    \n",
    "    # Registration options\n",
    "    registration=True,  # Enable registration\n",
    "    svort=True,  # Use SVoRT\n",
    "    svort_version='v2',  # 'v1' or 'v2'\n",
    "    use_vvr=False,  # Use traditional stack registration\n",
    "    force_vvr=False,\n",
    "    force_scanner=False,\n",
    "    \n",
    "    # Training options\n",
    "    skip_reconstruction=False,\n",
    "    n_iter=1000,  # Number of training iterations (increase for better quality)\n",
    "    n_epochs=None,\n",
    "    batch_size=4096,\n",
    "    learning_rate=0.01,\n",
    "    single_precision=False,  # Use FP32 instead of FP16\n",
    "    gamma=0.33,\n",
    "    milestones=[0.5, 0.75, 0.9],\n",
    "    n_samples=128 * 2,\n",
    "    \n",
    "    # Model architecture\n",
    "    coarsest_resolution=2.0,\n",
    "    finest_resolution=0.5,\n",
    "    level_scale=1.39,\n",
    "    n_features_per_level=2,\n",
    "    log2_hashmap_size=19,\n",
    "    width=64,\n",
    "    depth=2,\n",
    "    n_features_z=15,\n",
    "    n_features_slice=16,\n",
    "    no_transformation_optimization=False,\n",
    "    no_slice_scale=False,\n",
    "    no_pixel_variance=False,\n",
    "    no_slice_variance=False,\n",
    "    \n",
    "    # Regularization\n",
    "    weight_transformation=0.1,\n",
    "    weight_bias=0.1,\n",
    "    weight_image=0.01,\n",
    "    image_regularization='TV',  # 'none', 'TV', 'edge', 'L2'\n",
    "    weight_deform=0.1,\n",
    "    delta=0.2,\n",
    "    img_reg_autodiff=False,\n",
    "    \n",
    "    # Deformation options\n",
    "    deformable=False,\n",
    "    n_features_deform=8,\n",
    "    n_features_per_level_deform=4,\n",
    "    level_scale_deform=1.3819,\n",
    "    coarsest_resolution_deform=32.0,\n",
    "    finest_resolution_deform=8.0,\n",
    "    \n",
    "    # Sampling options\n",
    "    output_resolution=0.8,  # Output volume resolution in mm\n",
    "    n_inference_samples=128,\n",
    "    inference_batch_size=1024,\n",
    "    output_intensity_mean=None,\n",
    "    with_background=False,\n",
    "    \n",
    "    # Output files\n",
    "    output_volume='output_volume.nii.gz',\n",
    "    output_model='output_model.pt',\n",
    "    output_slices=None,\n",
    "    simulated_slices=None,\n",
    "    output_corrected_stacks=None,\n",
    "    output_stack_masks=None,\n",
    "    output_json='output_results.json',\n",
    "    \n",
    "    # System options\n",
    "    device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "    debug=False,\n",
    "    dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    ")\n",
    "\n",
    "print(\"Configuration created:\")\n",
    "print(f\"  Device: {args.device}\")\n",
    "print(f\"  Input stacks: {len(args.input_stacks)}\")\n",
    "print(f\"  Training iterations: {args.n_iter}\")\n",
    "print(f\"  Output resolution: {args.output_resolution} mm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Phase 1: Load Inputs\n",
    "\n",
    "Load input MRI stacks, masks, and any pre-trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"PHASE 1: LOADING INPUTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "input_dict = {}\n",
    "\n",
    "# Load input stacks\n",
    "if args.input_stacks is not None:\n",
    "    input_stacks = []\n",
    "    print(f\"\\nLoading {len(args.input_stacks)} input stacks...\")\n",
    "    \n",
    "    for i, f in enumerate(args.input_stacks):\n",
    "        if not os.path.exists(f):\n",
    "            print(f\"‚ö† Warning: File not found: {f}\")\n",
    "            continue\n",
    "            \n",
    "        stack = load_stack(\n",
    "            f,\n",
    "            args.stack_masks[i] if args.stack_masks is not None else None,\n",
    "            device=args.device,\n",
    "        )\n",
    "        \n",
    "        if args.thicknesses is not None:\n",
    "            stack.thickness = args.thicknesses[i]\n",
    "        \n",
    "        input_stacks.append(stack)\n",
    "        print(f\"‚úì Loaded stack {i + 1}: {f}\")\n",
    "    \n",
    "    input_dict[\"input_stacks\"] = input_stacks\n",
    "    print(f\"\\n‚úì Successfully loaded {len(input_stacks)} stacks\")\n",
    "\n",
    "# Load pre-trained model if provided\n",
    "if hasattr(args, 'input_model') and args.input_model is not None:\n",
    "    if os.path.exists(args.input_model):\n",
    "        print(f\"\\nLoading pre-trained model from {args.input_model}\")\n",
    "        cp = torch.load(args.input_model, map_location=args.device)\n",
    "        input_dict[\"model\"] = INR(cp[\"model\"][\"bounding_box\"], cp[\"args\"])\n",
    "        input_dict[\"model\"].load_state_dict(cp[\"model\"])\n",
    "        input_dict[\"mask\"] = cp[\"mask\"]\n",
    "        print(\"‚úì Model loaded successfully\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Input Stacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"input_stacks\" in input_dict:\n",
    "    for i, stack in enumerate(input_dict[\"input_stacks\"]):\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"STACK {i+1} ANALYSIS\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        # Show detailed information\n",
    "        show_stack_info(stack, i)\n",
    "        \n",
    "        # Show slice montage\n",
    "        show_slice_montage(stack, title=f\"Stack {i+1}: Slice Montage\", num_slices=9)\n",
    "        \n",
    "        # Show intensity histogram\n",
    "        show_intensity_histogram(stack, title=f\"Stack {i+1}: Intensity Distribution\")\n",
    "        \n",
    "        # Show 3D views if stack has enough slices\n",
    "        if stack.slices.shape[0] >= 10:\n",
    "            volume_data = stack.slices[:, 0, :, :]\n",
    "            show_3d_views(volume_data, title=f\"Stack {i+1}: 3D Views\")\n",
    "else:\n",
    "    print(\"No input stacks to visualize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Phase 2: Segmentation\n",
    "\n",
    "Apply 2D fetal brain segmentation to create masks for each slice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"PHASE 2: SEGMENTATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if args.segmentation and \"input_stacks\" in input_dict:\n",
    "    input_stacks = input_dict[\"input_stacks\"]\n",
    "    print(f\"\\nRunning brain segmentation on {len(input_stacks)} stacks...\")\n",
    "    \n",
    "    # Store original stacks for comparison\n",
    "    original_stacks = [stack.clone() for stack in input_stacks]\n",
    "    \n",
    "    # Run segmentation\n",
    "    segmented_stacks = brain_segmentation(input_stacks, args)\n",
    "    \n",
    "    input_dict[\"input_stacks\"] = segmented_stacks\n",
    "    input_dict[\"original_stacks\"] = original_stacks\n",
    "    \n",
    "    print(\"‚úì Segmentation completed\")\n",
    "else:\n",
    "    print(\"\\nSegmentation skipped (not enabled)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Segmentation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.segmentation and \"input_stacks\" in input_dict and \"original_stacks\" in input_dict:\n",
    "    for i, (orig_stack, seg_stack) in enumerate(zip(input_dict[\"original_stacks\"], input_dict[\"input_stacks\"])):\n",
    "        print(f\"\\nStack {i+1} - Segmentation Comparison\")\n",
    "        \n",
    "        # Compare before and after\n",
    "        compare_stacks(\n",
    "            orig_stack, \n",
    "            seg_stack, \n",
    "            title1=\"Before Segmentation\", \n",
    "            title2=\"After Segmentation\"\n",
    "        )\n",
    "        \n",
    "        # Show mask\n",
    "        if seg_stack.mask is not None:\n",
    "            mid_slice = seg_stack.mask.shape[0] // 2\n",
    "            plt.figure(figsize=(6, 6))\n",
    "            plt.imshow(seg_stack.mask[mid_slice, 0].cpu().numpy().T, cmap='binary', origin='lower')\n",
    "            plt.title(f\"Stack {i+1}: Segmentation Mask (Slice {mid_slice})\")\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "else:\n",
    "    print(\"No segmentation results to visualize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Phase 3: Bias Field Correction\n",
    "\n",
    "Apply N4 bias field correction to remove intensity inhomogeneities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"PHASE 3: BIAS FIELD CORRECTION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if args.bias_field_correction and \"input_stacks\" in input_dict:\n",
    "    input_stacks = input_dict[\"input_stacks\"]\n",
    "    print(f\"\\nRunning N4 bias field correction on {len(input_stacks)} stacks...\")\n",
    "    \n",
    "    # Store uncorrected stacks for comparison\n",
    "    uncorrected_stacks = [stack.clone() for stack in input_stacks]\n",
    "    \n",
    "    corrected_stacks = []\n",
    "    for i, stack in enumerate(tqdm(input_stacks, desc=\"Bias correction\")):\n",
    "        corrected_stack = n4_bias_field_correction(stack)\n",
    "        corrected_stacks.append(corrected_stack)\n",
    "    \n",
    "    input_dict[\"input_stacks\"] = corrected_stacks\n",
    "    input_dict[\"uncorrected_stacks\"] = uncorrected_stacks\n",
    "    input_dict[\"output_corrected_stacks\"] = corrected_stacks\n",
    "    \n",
    "    print(\"‚úì Bias field correction completed\")\n",
    "else:\n",
    "    print(\"\\nBias field correction skipped (not enabled)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Bias Correction Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.bias_field_correction and \"uncorrected_stacks\" in input_dict:\n",
    "    for i, (uncorr_stack, corr_stack) in enumerate(zip(input_dict[\"uncorrected_stacks\"], input_dict[\"input_stacks\"])):\n",
    "        print(f\"\\nStack {i+1} - Bias Correction Comparison\")\n",
    "        \n",
    "        # Compare before and after\n",
    "        compare_stacks(\n",
    "            uncorr_stack, \n",
    "            corr_stack, \n",
    "            title1=\"Before Correction\", \n",
    "            title2=\"After Correction\"\n",
    "        )\n",
    "        \n",
    "        # Show histograms\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "        \n",
    "        data_before = uncorr_stack.slices[uncorr_stack.slices > 0].cpu().numpy().flatten()\n",
    "        data_after = corr_stack.slices[corr_stack.slices > 0].cpu().numpy().flatten()\n",
    "        \n",
    "        axes[0].hist(data_before, bins=50, alpha=0.7, edgecolor='black')\n",
    "        axes[0].set_title(f\"Stack {i+1}: Before Correction\")\n",
    "        axes[0].set_xlabel('Intensity')\n",
    "        axes[0].set_ylabel('Frequency')\n",
    "        \n",
    "        axes[1].hist(data_after, bins=50, alpha=0.7, edgecolor='black', color='orange')\n",
    "        axes[1].set_title(f\"Stack {i+1}: After Correction\")\n",
    "        axes[1].set_xlabel('Intensity')\n",
    "        axes[1].set_ylabel('Frequency')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"No bias correction results to visualize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Phase 4: Quality Assessment\n",
    "\n",
    "Assess the quality of input stacks using various metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"PHASE 4: QUALITY ASSESSMENT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if not args.skip_assessment and \"input_stacks\" in input_dict:\n",
    "    input_stacks = input_dict[\"input_stacks\"]\n",
    "    print(f\"\\nAssessing quality of {len(input_stacks)} stacks...\")\n",
    "    print(f\"Metric: {args.metric}\")\n",
    "    print(f\"Filter method: {args.filter_method}\")\n",
    "    \n",
    "    augmentation = not args.no_augmentation_assess\n",
    "    \n",
    "    filtered_stacks, assessment_results = assess(\n",
    "        input_stacks,\n",
    "        args.metric,\n",
    "        args.filter_method,\n",
    "        args.cutoff or 0.0,\n",
    "        args.batch_size_assess,\n",
    "        augmentation,\n",
    "        args.device,\n",
    "    )\n",
    "    \n",
    "    input_dict[\"input_stacks\"] = filtered_stacks\n",
    "    input_dict[\"assessment_results\"] = assessment_results\n",
    "    \n",
    "    print(\"\\n‚úì Assessment completed\")\n",
    "    print(f\"\\nQuality Scores:\")\n",
    "    for i, score in enumerate(assessment_results):\n",
    "        print(f\"  Stack {i+1}: {score}\")\n",
    "else:\n",
    "    print(\"\\nQuality assessment skipped\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Assessment Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"assessment_results\" in input_dict:\n",
    "    results = input_dict[\"assessment_results\"]\n",
    "    \n",
    "    # Bar plot of quality scores\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "    stack_indices = np.arange(len(results))\n",
    "    \n",
    "    ax.bar(stack_indices, results, alpha=0.7, edgecolor='black')\n",
    "    ax.set_xlabel('Stack Index')\n",
    "    ax.set_ylabel(f'Quality Score ({args.metric})')\n",
    "    ax.set_title('Stack Quality Assessment')\n",
    "    ax.set_xticks(stack_indices)\n",
    "    ax.set_xticklabels([f'Stack {i+1}' for i in stack_indices])\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No assessment results to visualize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Phase 5: Registration (Motion Correction)\n",
    "\n",
    "Apply SVoRT registration to correct for motion between slices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"PHASE 5: REGISTRATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if args.registration and \"input_stacks\" in input_dict:\n",
    "    input_stacks = input_dict[\"input_stacks\"]\n",
    "    print(f\"\\nRunning registration on {len(input_stacks)} stacks...\")\n",
    "    print(f\"SVoRT: {args.svort}\")\n",
    "    print(f\"SVoRT version: {args.svort_version}\")\n",
    "    \n",
    "    if args.svort:\n",
    "        from preprocess.svort import svort_predict\n",
    "        \n",
    "        registered_slices = svort_predict(\n",
    "            dataset=input_stacks,\n",
    "            device=args.device,\n",
    "            svort_version=args.svort_version,\n",
    "            svort=True,\n",
    "            vvr=args.use_vvr,\n",
    "            force_vvr=args.force_vvr,\n",
    "            force_scanner=args.force_scanner,\n",
    "        )\n",
    "        \n",
    "        input_dict[\"input_slices\"] = registered_slices\n",
    "        print(f\"\\n‚úì SVoRT registration completed: {len(registered_slices)} slices\")\n",
    "    else:\n",
    "        # Convert stacks to slices without registration\n",
    "        slices = []\n",
    "        for stack in input_stacks:\n",
    "            for i in range(stack.slices.shape[0]):\n",
    "                slice_img = stack.slices[i]\n",
    "                slice_mask = stack.mask[i] if stack.mask is not None else None\n",
    "                slice_obj = Slice(\n",
    "                    slice_img,\n",
    "                    slice_mask,\n",
    "                    stack.transformation[i],\n",
    "                    stack.resolution_x,\n",
    "                    stack.resolution_y,\n",
    "                    stack.thickness,\n",
    "                )\n",
    "                slices.append(slice_obj)\n",
    "        input_dict[\"input_slices\"] = slices\n",
    "        print(f\"\\n‚úì Created {len(slices)} slices from stacks (no registration)\")\n",
    "else:\n",
    "    print(\"\\nRegistration skipped\")\n",
    "    # Still need to convert to slices\n",
    "    if \"input_stacks\" in input_dict and \"input_slices\" not in input_dict:\n",
    "        slices = []\n",
    "        for stack in input_dict[\"input_stacks\"]:\n",
    "            for i in range(stack.slices.shape[0]):\n",
    "                slice_img = stack.slices[i]\n",
    "                slice_mask = stack.mask[i] if stack.mask is not None else None\n",
    "                slice_obj = Slice(\n",
    "                    slice_img,\n",
    "                    slice_mask,\n",
    "                    stack.transformation[i],\n",
    "                    stack.resolution_x,\n",
    "                    stack.resolution_y,\n",
    "                    stack.thickness,\n",
    "                )\n",
    "                slices.append(slice_obj)\n",
    "        input_dict[\"input_slices\"] = slices\n",
    "        print(f\"\\n‚úì Created {len(slices)} slices from stacks\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Registration Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"input_slices\" in input_dict:\n",
    "    slices = input_dict[\"input_slices\"]\n",
    "    \n",
    "    print(f\"\\nTotal slices after registration: {len(slices)}\")\n",
    "    print(f\"\\nSlice Information:\")\n",
    "    print(f\"  First slice shape: {slices[0].image.shape}\")\n",
    "    print(f\"  Resolution (x, y): {slices[0].resolution_x:.3f} mm, {slices[0].resolution_y:.3f} mm\")\n",
    "    print(f\"  Thickness: {slices[0].thickness:.3f} mm\")\n",
    "    print(f\"  Data type: {slices[0].image.dtype}\")\n",
    "    print(f\"  Device: {slices[0].image.device}\")\n",
    "    \n",
    "    # Show sample slices\n",
    "    num_samples = min(9, len(slices))\n",
    "    sample_indices = np.linspace(0, len(slices) - 1, num_samples, dtype=int)\n",
    "    \n",
    "    rows = int(np.ceil(np.sqrt(num_samples)))\n",
    "    cols = int(np.ceil(num_samples / rows))\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols * 3, rows * 3))\n",
    "    axes = axes.flatten() if num_samples > 1 else [axes]\n",
    "    \n",
    "    for idx, ax in enumerate(axes):\n",
    "        if idx < num_samples:\n",
    "            slice_idx = sample_indices[idx]\n",
    "            slice_data = slices[slice_idx].image[0].cpu().numpy()\n",
    "            \n",
    "            ax.imshow(slice_data.T, cmap='gray', origin='lower')\n",
    "            ax.set_title(f'Slice {slice_idx}/{len(slices)-1}')\n",
    "            ax.axis('off')\n",
    "        else:\n",
    "            ax.axis('off')\n",
    "    \n",
    "    plt.suptitle(\"Registered Slices Sample\", fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No registered slices to visualize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Phase 6: Reconstruction (Training)\n",
    "\n",
    "Train the NeSVoR model using the registered slices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"PHASE 6: RECONSTRUCTION (TRAINING)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if not args.skip_reconstruction and \"input_slices\" in input_dict:\n",
    "    input_slices = input_dict[\"input_slices\"]\n",
    "    \n",
    "    print(f\"\\nTraining NeSVoR model on {len(input_slices)} slices\")\n",
    "    print(f\"Training iterations: {args.n_iter}\")\n",
    "    print(f\"Batch size: {args.batch_size}\")\n",
    "    print(f\"Learning rate: {args.learning_rate}\")\n",
    "    print(f\"Device: {args.device}\")\n",
    "    print(f\"Precision: {'FP16' if not args.single_precision else 'FP32'}\")\n",
    "    print(\"\\nStarting training...\\n\")\n",
    "    \n",
    "    # Add progress bar for notebook\n",
    "    args.progress_bar = tqdm(total=args.n_iter, desc=\"Training\", unit=\"iter\")\n",
    "    \n",
    "    try:\n",
    "        # Train model\n",
    "        model, output_slices, mask = train(input_slices, args)\n",
    "        \n",
    "        input_dict[\"output_model\"] = model\n",
    "        input_dict[\"output_slices\"] = output_slices\n",
    "        input_dict[\"mask\"] = mask\n",
    "        \n",
    "        print(\"\\n‚úì Training completed successfully\")\n",
    "    finally:\n",
    "        if hasattr(args, 'progress_bar') and args.progress_bar is not None:\n",
    "            args.progress_bar.close()\n",
    "            delattr(args, 'progress_bar')\n",
    "else:\n",
    "    print(\"\\nReconstruction skipped\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Model Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"output_model\" in input_dict:\n",
    "    model = input_dict[\"output_model\"]\n",
    "    mask = input_dict[\"mask\"]\n",
    "    \n",
    "    print(\"\\nTrained Model Information:\")\n",
    "    print(f\"  Model type: {type(model).__name__}\")\n",
    "    print(f\"  Bounding box: {model.bounding_box}\")\n",
    "    \n",
    "    # Count parameters\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"  Total parameters: {total_params:,}\")\n",
    "    print(f\"  Trainable parameters: {trainable_params:,}\")\n",
    "    \n",
    "    print(f\"\\nMask Information:\")\n",
    "    print(f\"  Mask shape: {mask.image.shape}\")\n",
    "    print(f\"  Mask resolution: {mask.resolution_x:.3f} mm\")\n",
    "    print(f\"  Masked voxels: {mask.image.sum().item():,}\")\n",
    "    \n",
    "    # Visualize mask\n",
    "    show_3d_views(mask.image[0], title=\"Reconstruction Mask\")\n",
    "else:\n",
    "    print(\"No trained model to visualize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Phase 7: Sampling\n",
    "\n",
    "Sample high-resolution volume from the trained implicit neural representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"PHASE 7: SAMPLING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if args.output_volume and \"output_model\" in input_dict:\n",
    "    model = input_dict[\"output_model\"]\n",
    "    mask = input_dict[\"mask\"]\n",
    "    \n",
    "    print(f\"\\nSampling volume at {args.output_resolution} mm resolution\")\n",
    "    print(f\"Number of PSF samples: {args.n_inference_samples}\")\n",
    "    print(f\"Batch size: {args.inference_batch_size}\")\n",
    "    print(\"\\nSampling...\")\n",
    "    \n",
    "    # Sample volume\n",
    "    output_volume = sample_volume(\n",
    "        model,\n",
    "        mask,\n",
    "        psf_resolution=args.output_resolution,\n",
    "        batch_size=args.inference_batch_size,\n",
    "        n_samples=args.n_inference_samples,\n",
    "    )\n",
    "    \n",
    "    input_dict[\"output_volume\"] = output_volume\n",
    "    \n",
    "    print(f\"\\n‚úì Volume sampled: shape={output_volume.image.shape}\")\n",
    "    print(f\"  Resolution: {output_volume.resolution_x:.3f} mm\")\n",
    "    print(f\"  Intensity range: [{output_volume.image.min().item():.2f}, {output_volume.image.max().item():.2f}]\")\n",
    "    \n",
    "    # Sample simulated slices if requested\n",
    "    if args.simulated_slices and \"output_slices\" in input_dict:\n",
    "        print(\"\\nSampling simulated slices...\")\n",
    "        output_slices = input_dict[\"output_slices\"]\n",
    "        \n",
    "        simulated = sample_slices(\n",
    "            model,\n",
    "            output_slices,\n",
    "            mask,\n",
    "            output_psf_factor=1.0,\n",
    "            n_samples=args.n_inference_samples,\n",
    "        )\n",
    "        \n",
    "        input_dict[\"simulated_slices\"] = simulated\n",
    "        print(f\"‚úì Sampled {len(simulated)} simulated slices\")\n",
    "else:\n",
    "    print(\"\\nSampling skipped (no output volume requested or model not trained)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Output Volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"output_volume\" in input_dict:\n",
    "    volume = input_dict[\"output_volume\"]\n",
    "    \n",
    "    print(\"\\nOutput Volume Information:\")\n",
    "    print(f\"  Shape: {volume.image.shape}\")\n",
    "    print(f\"  Resolution: {volume.resolution_x:.3f} mm\")\n",
    "    print(f\"  Data type: {volume.image.dtype}\")\n",
    "    print(f\"  Intensity range: [{volume.image.min().item():.2f}, {volume.image.max().item():.2f}]\")\n",
    "    print(f\"  Mean intensity: {volume.image.mean().item():.2f}\")\n",
    "    \n",
    "    # Show 3D orthogonal views\n",
    "    show_3d_views(volume.image[0], title=\"Output Volume: Orthogonal Views\")\n",
    "    \n",
    "    # Show intensity histogram\n",
    "    data = volume.image[volume.image > 0].cpu().numpy().flatten()\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 4))\n",
    "    ax.hist(data, bins=50, alpha=0.7, edgecolor='black', color='green')\n",
    "    ax.set_xlabel('Intensity')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.set_title('Output Volume: Intensity Distribution')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Interactive slider for exploring slices\n",
    "    from ipywidgets import interact, IntSlider\n",
    "    \n",
    "    def show_slice(axis, slice_idx):\n",
    "        \"\"\"Interactive slice viewer.\"\"\"\n",
    "        vol_data = volume.image[0].cpu().numpy()\n",
    "        \n",
    "        if axis == 0:  # Sagittal\n",
    "            slice_data = vol_data[slice_idx, :, :]\n",
    "            title = f'Sagittal (YZ) - Slice {slice_idx}/{vol_data.shape[0]-1}'\n",
    "        elif axis == 1:  # Coronal\n",
    "            slice_data = vol_data[:, slice_idx, :]\n",
    "            title = f'Coronal (XZ) - Slice {slice_idx}/{vol_data.shape[1]-1}'\n",
    "        else:  # Axial\n",
    "            slice_data = vol_data[:, :, slice_idx]\n",
    "            title = f'Axial (XY) - Slice {slice_idx}/{vol_data.shape[2]-1}'\n",
    "        \n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(slice_data.T, cmap='gray', origin='lower')\n",
    "        plt.title(title)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    \n",
    "    # Create interactive viewer\n",
    "    vol_shape = volume.image[0].shape\n",
    "    print(\"\\nüìä Interactive Slice Viewer:\")\n",
    "    interact(\n",
    "        show_slice,\n",
    "        axis=IntSlider(min=0, max=2, step=1, value=2, description='Axis:'),\n",
    "        slice_idx=IntSlider(min=0, max=max(vol_shape)-1, step=1, value=max(vol_shape)//2, description='Slice:')\n",
    "    )\n",
    "else:\n",
    "    print(\"No output volume to visualize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Input vs Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"input_stacks\" in input_dict and \"output_volume\" in input_dict:\n",
    "    print(\"\\nüìä Input vs Output Comparison\")\n",
    "    \n",
    "    # Get first input stack for comparison\n",
    "    input_stack = input_dict[\"input_stacks\"][0]\n",
    "    output_volume = input_dict[\"output_volume\"]\n",
    "    \n",
    "    print(f\"\\nInput Stack (Stack 0):\")\n",
    "    print(f\"  Shape: {input_stack.slices.shape}\")\n",
    "    print(f\"  Resolution: {input_stack.resolution_x:.3f} mm x {input_stack.resolution_y:.3f} mm\")\n",
    "    print(f\"  Thickness: {input_stack.thickness:.3f} mm\")\n",
    "    \n",
    "    print(f\"\\nOutput Volume:\")\n",
    "    print(f\"  Shape: {output_volume.image.shape}\")\n",
    "    print(f\"  Resolution: {output_volume.resolution_x:.3f} mm (isotropic)\")\n",
    "    \n",
    "    # Show side-by-side comparison\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    \n",
    "    # Input stack middle slice\n",
    "    mid_slice = input_stack.slices.shape[0] // 2\n",
    "    axes[0].imshow(input_stack.slices[mid_slice, 0].cpu().numpy().T, cmap='gray', origin='lower')\n",
    "    axes[0].set_title(f'Input Stack 0\\n(Slice {mid_slice}, {input_stack.thickness:.1f}mm thick)')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Output volume middle slice\n",
    "    mid_z = output_volume.image.shape[3] // 2\n",
    "    axes[1].imshow(output_volume.image[0, :, :, mid_z].cpu().numpy().T, cmap='gray', origin='lower')\n",
    "    axes[1].set_title(f'Output Volume\\n(Axial slice, {output_volume.resolution_x:.1f}mm isotropic)')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    plt.suptitle('Resolution Comparison: Input vs Output', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Cannot compare - missing input or output data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Phase 8: Save Outputs\n",
    "\n",
    "Save all generated outputs to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"PHASE 8: SAVE OUTPUTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Save output volume\n",
    "if args.output_volume and \"output_volume\" in input_dict:\n",
    "    print(f\"\\nSaving output volume to {args.output_volume}\")\n",
    "    volume = input_dict[\"output_volume\"]\n",
    "    \n",
    "    # Rescale if requested\n",
    "    if args.output_intensity_mean is not None:\n",
    "        volume.rescale(args.output_intensity_mean)\n",
    "    \n",
    "    volume.save(args.output_volume, masked=not args.with_background)\n",
    "    print(f\"‚úì Volume saved\")\n",
    "\n",
    "# Save trained model\n",
    "if args.output_model and \"output_model\" in input_dict:\n",
    "    print(f\"\\nSaving model to {args.output_model}\")\n",
    "    torch.save(\n",
    "        {\n",
    "            \"model\": input_dict[\"output_model\"].state_dict(),\n",
    "            \"mask\": input_dict[\"mask\"],\n",
    "            \"args\": args,\n",
    "        },\n",
    "        args.output_model,\n",
    "    )\n",
    "    print(f\"‚úì Model saved\")\n",
    "\n",
    "# Save output slices\n",
    "if args.output_slices and \"output_slices\" in input_dict:\n",
    "    print(f\"\\nSaving output slices to {args.output_slices}\")\n",
    "    save_slices(args.output_slices, input_dict[\"output_slices\"], sep=True)\n",
    "    print(f\"‚úì Slices saved\")\n",
    "\n",
    "# Save simulated slices\n",
    "if args.simulated_slices and \"simulated_slices\" in input_dict:\n",
    "    print(f\"\\nSaving simulated slices to {args.simulated_slices}\")\n",
    "    save_slices(args.simulated_slices, input_dict[\"simulated_slices\"], sep=False)\n",
    "    print(f\"‚úì Simulated slices saved\")\n",
    "\n",
    "# Save JSON results\n",
    "if args.output_json:\n",
    "    print(f\"\\nSaving configuration and results to {args.output_json}\")\n",
    "    output_data = vars(args).copy()\n",
    "    \n",
    "    # Convert device to serializable format\n",
    "    if \"device\" in output_data:\n",
    "        output_data[\"device\"] = str(output_data[\"device\"])\n",
    "    if \"dtype\" in output_data:\n",
    "        output_data[\"dtype\"] = str(output_data[\"dtype\"])\n",
    "    if \"progress_bar\" in output_data:\n",
    "        del output_data[\"progress_bar\"]\n",
    "    \n",
    "    # Add assessment results if available\n",
    "    if \"assessment_results\" in input_dict:\n",
    "        output_data[\"assessment_results\"] = input_dict[\"assessment_results\"]\n",
    "    \n",
    "    with open(args.output_json, \"w\") as f:\n",
    "        json.dump(output_data, f, indent=2)\n",
    "    print(f\"‚úì Results saved\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úì PIPELINE COMPLETED SUCCESSFULLY\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Summary\n",
    "\n",
    "Display a summary of the entire pipeline execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PIPELINE SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüì• Input:\")\n",
    "if \"input_stacks\" in input_dict:\n",
    "    print(f\"  Number of stacks: {len(input_dict['input_stacks'])}\")\n",
    "    for i, stack in enumerate(input_dict[\"input_stacks\"]):\n",
    "        print(f\"    Stack {i+1}: {stack.slices.shape[0]} slices, {stack.resolution_x:.2f}mm resolution\")\n",
    "\n",
    "print(\"\\n‚öôÔ∏è  Processing:\")\n",
    "print(f\"  Segmentation: {'‚úì Applied' if args.segmentation else '‚úó Skipped'}\")\n",
    "print(f\"  Bias correction: {'‚úì Applied' if args.bias_field_correction else '‚úó Skipped'}\")\n",
    "print(f\"  Assessment: {'‚úì Applied' if not args.skip_assessment else '‚úó Skipped'}\")\n",
    "print(f\"  Registration: {'‚úì Applied (SVoRT ' + args.svort_version + ')' if args.registration else '‚úó Skipped'}\")\n",
    "\n",
    "if \"input_slices\" in input_dict:\n",
    "    print(f\"\\n  Total slices for reconstruction: {len(input_dict['input_slices'])}\")\n",
    "\n",
    "if \"output_model\" in input_dict:\n",
    "    model = input_dict[\"output_model\"]\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"\\nüß† Model:\")\n",
    "    print(f\"  Training iterations: {args.n_iter}\")\n",
    "    print(f\"  Total parameters: {total_params:,}\")\n",
    "    print(f\"  Precision: {'FP16' if not args.single_precision else 'FP32'}\")\n",
    "\n",
    "if \"output_volume\" in input_dict:\n",
    "    volume = input_dict[\"output_volume\"]\n",
    "    print(f\"\\nüì§ Output:\")\n",
    "    print(f\"  Volume shape: {volume.image.shape}\")\n",
    "    print(f\"  Resolution: {volume.resolution_x:.3f} mm (isotropic)\")\n",
    "    print(f\"  File: {args.output_volume}\")\n",
    "    \n",
    "    if args.output_model:\n",
    "        print(f\"  Model: {args.output_model}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ All tasks completed!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
